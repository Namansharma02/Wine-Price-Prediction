{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BL_a-BTFZp-f"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "CNS4OEeahv8o",
    "outputId": "4c056cf6-ad83-4800-8fce-2d53b20dccfc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have tensorflow version  1.7.0\n"
     ]
    }
   ],
   "source": [
    "#import the important modules\n",
    "\n",
    "import itertools\n",
    "import os #operating system\n",
    "import math #math operations\n",
    "import numpy as np #arrays\n",
    "import pandas as pd #dataframes\n",
    "import tensorflow as tf #dataflow programming\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import keras\n",
    "\n",
    "layers=keras.layers\n",
    "\n",
    "print(\"You have tensorflow version \" , tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might get accuracy at the last like acc:0000e+00 because of the tensorflow version 1.12. I had to install 1.7 again and then it worked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the data from the source\n",
    "URL = \"https://storage.googleapis.com/sara-cloud-ml/wine_data.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "ppTZhyRwjbab",
    "outputId": "19fc780f-3e30-4979-cb07-e0f73de9d247"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wine_data.csv\n"
     ]
    }
   ],
   "source": [
    "#get the data from the source\n",
    "\n",
    "path = 'wine_data.csv'\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XjiaqhpTkNMV"
   },
   "outputs": [],
   "source": [
    "#convert data from csv to pandas file\n",
    "data = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "colab_type": "code",
    "id": "USzcM6UxkmEI",
    "outputId": "af4d4232-09c6-40a5-d0e4-b591a581b379"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74046</th>\n",
       "      <td>74046</td>\n",
       "      <td>Spain</td>\n",
       "      <td>This is gritty, burnt and stalky smelling. On ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Central Spain</td>\n",
       "      <td>Vino de la Tierra de Castilla</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tempranillo-Shiraz</td>\n",
       "      <td>Volteo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67803</th>\n",
       "      <td>67803</td>\n",
       "      <td>Italy</td>\n",
       "      <td>The strong start—a nose full of slightly candi...</td>\n",
       "      <td>Pratale</td>\n",
       "      <td>84</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Tuscany</td>\n",
       "      <td>Chianti Classico</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sangiovese</td>\n",
       "      <td>Coli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57195</th>\n",
       "      <td>57195</td>\n",
       "      <td>US</td>\n",
       "      <td>Greenwood Ridge often does a good job at Sauvi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>18.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Anderson Valley</td>\n",
       "      <td>Mendocino/Lake Counties</td>\n",
       "      <td>Sauvignon Blanc</td>\n",
       "      <td>Greenwood Ridge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133375</th>\n",
       "      <td>133375</td>\n",
       "      <td>US</td>\n",
       "      <td>A light entry holds flavors of strawberry and ...</td>\n",
       "      <td>Renegade Ridge Estate</td>\n",
       "      <td>85</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Dundee Hills</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Archery Summit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>218</td>\n",
       "      <td>France</td>\n",
       "      <td>Paradis is a parcel within the Pfingstberg Gra...</td>\n",
       "      <td>Pfingstberg Paradis Grand Cru</td>\n",
       "      <td>93</td>\n",
       "      <td>42.0</td>\n",
       "      <td>Alsace</td>\n",
       "      <td>Alsace</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Riesling</td>\n",
       "      <td>Domaine François Schmitt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0 country                                        description  \\\n",
       "74046        74046   Spain  This is gritty, burnt and stalky smelling. On ...   \n",
       "67803        67803   Italy  The strong start—a nose full of slightly candi...   \n",
       "57195        57195      US  Greenwood Ridge often does a good job at Sauvi...   \n",
       "133375      133375      US  A light entry holds flavors of strawberry and ...   \n",
       "218            218  France  Paradis is a parcel within the Pfingstberg Gra...   \n",
       "\n",
       "                          designation  points  price       province  \\\n",
       "74046                             NaN      81   10.0  Central Spain   \n",
       "67803                         Pratale      84   19.0        Tuscany   \n",
       "57195                             NaN      80   18.0     California   \n",
       "133375          Renegade Ridge Estate      85   75.0         Oregon   \n",
       "218     Pfingstberg Paradis Grand Cru      93   42.0         Alsace   \n",
       "\n",
       "                             region_1                 region_2  \\\n",
       "74046   Vino de la Tierra de Castilla                      NaN   \n",
       "67803                Chianti Classico                      NaN   \n",
       "57195                 Anderson Valley  Mendocino/Lake Counties   \n",
       "133375                   Dundee Hills        Willamette Valley   \n",
       "218                            Alsace                      NaN   \n",
       "\n",
       "                   variety                    winery  \n",
       "74046   Tempranillo-Shiraz                    Volteo  \n",
       "67803           Sangiovese                      Coli  \n",
       "57195      Sauvignon Blanc           Greenwood Ridge  \n",
       "133375          Pinot Noir            Archery Summit  \n",
       "218               Riesling  Domaine François Schmitt  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shuffle the data\n",
    "data = data.sample(frac=1)\n",
    "\n",
    "#print first 5 rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yjt3P661kmer"
   },
   "outputs": [],
   "source": [
    "#do some preprocessing to limit the no. of varities in the dataset\n",
    "\n",
    "data = data[pd.notnull(data['country'])]\n",
    "data = data[pd.notnull(data['price'])]\n",
    "data = data.drop(data.columns[0],axis=1) # drop labels from index(axis) 1\n",
    "\n",
    "variety_threshold = 500 #any variety less than 500 will be removed.\n",
    "value_counts = data['variety'].value_counts() #total number of variety with names\n",
    "to_remove=value_counts[value_counts<=variety_threshold].index \n",
    "data.replace(to_remove,np.nan,inplace=True) #replacing variety with nan \n",
    "data=data[pd.notnull(data['variety'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "O3dQCk1Lkm1U",
    "outputId": "24f21a6d-33a8-4ea3-fc70-73061b9b0551"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 95646\n",
      "Test size: 23912\n"
     ]
    }
   ],
   "source": [
    "#split the dataset into train and test\n",
    "train_size=int(len(data)*.8)\n",
    "print(\"Train size: %d\" % train_size)\n",
    "print(\"Test size: %d\" % (len(data)-train_size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract training and testing features and all of the label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bvM2yQoxknLW"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Train features\n",
    "description_train = data['description'][:train_size]\n",
    "variety_train = data['variety'][:train_size]\n",
    "\n",
    "#train labels\n",
    "labels_train=data['price'][:train_size]\n",
    "\n",
    "#test features\n",
    "description_test = data['description'][train_size:]\n",
    "variety_test = data['variety'][train_size:]\n",
    "\n",
    "#test labels\n",
    "labels_test=data['price'][train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now instead of looking at every word in the description lets limit it to top 12000 words and it can be done through the keras built-in function.\n",
    "\n",
    "This is considered as wide because the input to each of our model for each description\n",
    "will be a 12000 element wide vector with zeroes and ones indicating the presence of the word in our\n",
    "vocabulary in a particular description.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9F_QaufjknZQ"
   },
   "outputs": [],
   "source": [
    "\n",
    "#create a tokenizer to preprocess our text descriptions\n",
    "vocab_size = 12000 #this is a hyperparameter\n",
    "\n",
    "tokenize = keras.preprocessing.text.Tokenizer(num_words=vocab_size,char_level=False)\n",
    "\n",
    "tokenize.fit_on_texts(description_train) #only fit on train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay so now that done we'll be actually using text to matrix function\n",
    "to convert each description to a bag of words vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VGLYNkLVwjR-"
   },
   "outputs": [],
   "source": [
    "#Wide feature 1 : spare bag of words (bow) vocab_size vector\n",
    "\n",
    "description_bow_train = tokenize.texts_to_matrix(description_train)\n",
    "description_bow_test = tokenize.texts_to_matrix(description_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wide feature 2 : one hot vector for variety categories\n",
    "\n",
    "#use sklearn utility to convert label strings to numbered index\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(variety_train)\n",
    "variety_train = encoder.transform(variety_train)\n",
    "variety_test = encoder.transform(variety_test)\n",
    "num_classes = np.max(variety_train) +1 \n",
    "\n",
    "#convert labels into one hot\n",
    "\n",
    "variety_train = keras.utils.to_categorical(variety_train,num_classes)\n",
    "variety_test = keras.utils.to_categorical(variety_test,num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras has two APIs to build a model \n",
    "- Sequential and Functional api. \n",
    "and I am going to use the functional api.\n",
    "\n",
    "As it provides more flexibility and let us combine multiple inputs in our layer. \n",
    "Also make our wide and deep model combine into one. \n",
    "First we need to define an input layer as a 12K element vector for each vocabulary and then I will \n",
    "connect this to our dense output layer to generate the price prediction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define our wide model with functional api\n",
    "\n",
    "bow_inputs = layers.Input(shape=(vocab_size,))\n",
    "variety_inputs = layers.Input(shape=(num_classes,))\n",
    "merged_layer = layers.concatenate([bow_inputs,variety_inputs])\n",
    "merged_layer = layers.Dense(256,activation='relu')(merged_layer)\n",
    "predictions = layers.Dense(1)(merged_layer)\n",
    "wide_model =keras.Model(inputs=[bow_inputs,variety_inputs],outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " bow_inputs - Tensor(\"input_20:0\", shape=(?, 12000), dtype=float32) <br>\n",
    " variety_inputs - Tensor(\"input_21:0\", shape=(?, 40), dtype=float32) <br>\n",
    " merged_layer - Tensor(\"dense_20/Relu:0\", shape=(?, 256), dtype=float32)<br>\n",
    " prediction - Tensor(\"dense_21/BiasAdd:0\", shape=(?, 1), dtype=float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 12000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 12040)        0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          3082496     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            257         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,082,753\n",
      "Trainable params: 3,082,753\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#now print out the summary from wide model\n",
    "\n",
    "wide_model.compile(loss='mse' , optimizer='adam' ,metrics=['accuracy'])\n",
    "print(wide_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check https://keras.io/models/model/ for proper understanding of .compile() <br>\n",
    "loss(mse) = mean square error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a deep representation of wine description we'll represent it as an embedding . <br>\n",
    "Well there are lots of resources on word embedding but the short version is that they can provide the map word to vector so that the similar words are closer together in the vector space. <br>\n",
    "Where to convert the text description to an embedding layer we need to first convert each description to a vector of integers corresponding to each word in our vocabulary. <br>\n",
    "We can do this with keras text_to_sequences method and we'll use pad_sequences to add zeroes to description vector so \n",
    " that they all are the same length.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deep model feature: word embeddings of wine description\n",
    "\n",
    "train_embed = tokenize.texts_to_sequences(description_train)\n",
    "test_embed = tokenize.texts_to_sequences(description_test)\n",
    "\n",
    "max_seq_length = 170\n",
    "\n",
    "train_embed = keras.preprocessing.sequence.pad_sequences(\n",
    "    train_embed, maxlen=max_seq_length, padding=\"post\")\n",
    "test_embed = keras.preprocessing.sequence.pad_sequences(\n",
    "    test_embed, maxlen=max_seq_length, padding=\"post\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to create our embedding layer and then feed it to the deep model.\n",
    "Well there are to ways to create an embedding layer, we can use weights from the pretent embeddings or we can\n",
    "learn the embeddings from our vocabulary. \n",
    "Its best to experiment both and see which performs better.Here I am considering to use learning embeddings. \n",
    "Firstly i will define the shape of the input to our deep model and then will feed it to the embedding layer and here I am using an embedding layer with **8 dimensions** and the output\n",
    "of the embedding layer will be a **3 dimensional vector**.\n",
    "Inorder to connect our embedding layer to dense fully connected output layer we need to flatten it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 170, 8)            96000     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1360)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 1361      \n",
      "=================================================================\n",
      "Total params: 97,361\n",
      "Trainable params: 97,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# lets define the model and flatten it\n",
    "\n",
    "deep_inputs = layers.Input(shape=(max_seq_length,))\n",
    "embedding = layers.Embedding(vocab_size,8,input_length=max_seq_length)(deep_inputs)\n",
    "embedding = layers.Flatten()(embedding)\n",
    "embed_out = layers.Dense(1)(embedding)\n",
    "deep_model = keras.Model(inputs=deep_inputs,outputs=embed_out)\n",
    "print(deep_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model.compile(loss='mse' , optimizer='adam' ,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a layer that concatenates outputs from each of the model and then merged them into full connected dense layer \n",
    "and finally define a combined model that combined the input and the output from each one.\n",
    "since both models are predciting the same thing that is price, the outputs and the labels will be the same.\n",
    "also since the output of our models is a numeric value we dont need to do any preprocessing and it is already \n",
    "in a right format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 12000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 170)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 12040)        0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 170, 8)       96000       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          3082496     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1360)         0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            257         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            1361        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 2)            0           dense_2[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            3           concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 3,180,117\n",
      "Trainable params: 3,180,117\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Wide and deep models are defined,so now will combine them\n",
    "\n",
    "\n",
    "merged_out = layers.concatenate([wide_model.output,deep_model.output])\n",
    "merged_out = layers.Dense(1)(merged_out)\n",
    "combined_model = keras.Model(wide_model.input +[deep_model.input],merged_out)\n",
    "print(combined_model.summary())\n",
    "\n",
    "combined_model.compile(loss='mse' , optimizer='adam' ,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "95646/95646 [==============================] - 126s 1ms/step - loss: 1115.2351 - acc: 0.0287\n",
      "Epoch 2/10\n",
      "95646/95646 [==============================] - 157s 2ms/step - loss: 875.1368 - acc: 0.0387\n",
      "Epoch 3/10\n",
      "95646/95646 [==============================] - 137s 1ms/step - loss: 715.6234 - acc: 0.0423\n",
      "Epoch 4/10\n",
      "95646/95646 [==============================] - 118s 1ms/step - loss: 567.7784 - acc: 0.0475\n",
      "Epoch 5/10\n",
      "95646/95646 [==============================] - 128s 1ms/step - loss: 430.4036 - acc: 0.0556\n",
      "Epoch 6/10\n",
      "95646/95646 [==============================] - 119s 1ms/step - loss: 313.8748 - acc: 0.0651\n",
      "Epoch 7/10\n",
      "95646/95646 [==============================] - 130s 1ms/step - loss: 228.1054 - acc: 0.0759\n",
      "Epoch 8/10\n",
      "95646/95646 [==============================] - 131s 1ms/step - loss: 167.9296 - acc: 0.0875\n",
      "Epoch 9/10\n",
      "95646/95646 [==============================] - 117s 1ms/step - loss: 129.9479 - acc: 0.0972\n",
      "Epoch 10/10\n",
      "95646/95646 [==============================] - 121s 1ms/step - loss: 101.0193 - acc: 0.1058\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a5dc4ecf60>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "combined_model.fit([description_bow_train,variety_train]+[train_embed],labels_train, epochs=10 , batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23912/23912 [==============================] - 19s 796us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[525.3722583289607, 0.0687102709986287]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate\n",
    "\n",
    "combined_model.evaluate([description_bow_test,variety_test]+[test_embed],labels_test,batch_size = 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss decreased a lot and the accuracy increased too.\n",
    "For the first training with only 10 epochs the result is quite good and with more taining better results are surely expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "\n",
    "predictions = combined_model.predict([description_bow_test, variety_test] + [test_embed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This charming Sauvignon Blanc smells sweetly of fresh pears and honeydew with a sprinkling of powdered sugar. Full bodied but dry with concentrated white grapefruit flavors, its brightened by a nervy acidity and a refreshing minerality in the midpalate.\n",
      "Predicted:  23.698996 Actual:  20.0 \n",
      "\n",
      "Rich and sweet, with blackberry, chocolate, plum pudding and spice flavors, accented with fine acidity. Made from traditional Port varieties plus Petite Sirah, it's a bit watery. The score would soar if the fruity concentration were greater.\n",
      "Predicted:  55.410152 Actual:  55.0 \n",
      "\n",
      "Kudos to the winery for holding this estate grown wine back for five-plus years. The wine is now softly dry and enormously complex, showing blackberry and cherry liqueur flavors that are beginning to age into drier, earthier notes of dried fruits and minerals. Cofermentation with some Viognier adds the perfect touch of bright, citrusy acidity.\n",
      "Predicted:  33.536213 Actual:  38.0 \n",
      "\n",
      "Attractive wine, boasting a good balance between herbaceous Sauvignon Blanc and a more perfumed character from Muscadelle. It has a creamy character along with intense acidity, leaving a fresh taste in the mouth.\n",
      "Predicted:  33.35243 Actual:  11.0 \n",
      "\n",
      "Starts with intense black-fruit aromas and dark, smoky accents as well as baked berries, licorice and meat. In the mouth, it's a bit clumsy and amped up, with big tannins, extract and a mouthfeel that grabs. Flavors of berry fruit and mint are good, while the finish bounces toward a loud finish. Not what you'd call an elegant wine; it's more about ripeness, power and extract.\n",
      "Predicted:  40.374035 Actual:  41.0 \n",
      "\n",
      "Ripe, rich peach, pineapple and mango aromas lend a plump, opulent feel to this dry-style Riesling. The palate balances mineral intensity with streaks of peach and honeydew flavor and bristling lime acidity. Finishes long with a kiss of white blossoms.\n",
      "Predicted:  15.885018 Actual:  18.0 \n",
      "\n",
      "Dry and firm, this has tannins and an austere structure. It will remain severe, though as the tannins soften, the wine will become more round and develop into a true, food-friendly selection.\n",
      "Predicted:  37.187332 Actual:  19.0 \n",
      "\n",
      "A classic Shiraz nose of plum pudding and rubber leads to a medium-weight palate that's got a bit of depth to it, with undertones of humus and fall leaves. Fresh black fruit pops up briefly on the short, crisp finish. Drink up.\n",
      "Predicted:  5.907713 Actual:  10.0 \n",
      "\n",
      "On the austere side, with fruit that has considerable—perhaps too much—freshness. Berry flavors and tannins verge on stalky, and the acidity gives the wine a light aftertaste.\n",
      "Predicted:  44.2024 Actual:  47.0 \n",
      "\n",
      "Dark cherry red in color, this blend of Cinsault, Grenache Noir, Syrah and Tempranillo features a bouquet of cherry with a hint of green pepper. Flavors of raspberry, pomegranate, orange peel and spearmint are set in a web of soft tannins that fully announce themselves at the mouth-coating, minty finish.\n",
      "Predicted:  14.407083 Actual:  13.0 \n",
      "\n",
      "This tiny production Zin is Bella's best barrels Selection. It's quite good, avoiding the pitfalls of overly high alcohol and overextraction of fruit. Not that it's shy. Rich in blackberry jam, chocolate and currant flavors, it's well balanced, with soft tannins and just in time acidity providing a good structure.\n",
      "Predicted:  50.653587 Actual:  48.0 \n",
      "\n",
      "Tight and oaky at first, with aromas of lemon rind, maple and leather. Next up, cassis and black cherry appear in the mouth, which precedes a tight, chocolaty finish that features good length and manly tannins. Very tightly wound, and powerful.\n",
      "Predicted:  48.901436 Actual:  20.0 \n",
      "\n",
      "A serious, intense wine, a success for the vintage, with its dusty tannins, solid blackberry fruits and a firm core. The wine is weighty, maybe just giving a green pepper hint, but generally sitting foursquare in the mouth.\n",
      "Predicted:  16.623081 Actual:  30.0 \n",
      "\n",
      "A bit more direct than the '05, which must be due to the so-so vintage. The wine is soft and immediately appealing for its red berry pie filling, red currant, baking spice, green olive tapenade and oak flavors. Should develop for years in the bottle, without necessarily gaining additional complexity.\n",
      "Predicted:  56.70682 Actual:  60.0 \n",
      "\n",
      "High alcohol gives this Pinot some heat, but it also lends incredible richness and ripeness to the flavors, which range from raspberry jam and cherry pie filling to buttered toast, creamy vanilla and exotic spice. A delicious and heady offering from Napa Cabernet specialist Hall winery.\n",
      "Predicted:  56.190487 Actual:  60.0 \n",
      "\n",
      "This is hard in tannins and firm in acidity, which gives it fine structure. It's not shy in flavor, and it offers waves of blackberries, black currants and cassis liqueur, plus a note of toasty new oak. While it could develop well with age, the forward fruit suggests drinking it over the next five years.\n",
      "Predicted:  45.35837 Actual:  40.0 \n",
      "\n",
      "Tight and restrained aromas of just-opening white blossoms are laid against a brioche backdrop with hints of spring grass too. It's very high toned on the palate, driven by limestone minerality with an acidic zing powered by lemon juice and lime peels. The apple flavors pick up a unique but pleasant sense of crushed, dried herbs as well.\n",
      "Predicted:  24.715227 Actual:  55.0 \n",
      "\n",
      "The top-of-the-range red from Casa de Santar estate in homage to the first count of Santar in the 18th century. It is a powerfully velvet wine, very elegant, packed with ripe tannins, dark fruits and a structure that demands aging. Keep for at least six years.\n",
      "Predicted:  59.99159 Actual:  60.0 \n",
      "\n",
      "A faint yeastiness subsides to expose luxurious aromas of violet, white peach and green herb on this single-vineyard Riesling. Lushly textured with flavors of yellow cherry and stone fruit, it has a steely, minerally tone that persists through the long finish.\n",
      "Predicted:  30.792723 Actual:  27.0 \n",
      "\n",
      "Interesting in that this fresh, snappy table wine includes 60% Airen (a white grape) in addition to Tempranillo. This odd combo results in a light-bodied, almost translucent wine that's easy to drink but offers little in the way of heft or complexity.\n",
      "Predicted:  5.959833 Actual:  6.0 \n",
      "\n",
      "With fairly muted fruit flavors and a hint of green pepper, this lighter-bodied and easy-drinking wine will pair well with most meat or chicken entrées. Flash-pasteurized and mevushal, this is a blend of 50% Cab, 30% Merlot and 20% Shiraz.\n",
      "Predicted:  8.796399 Actual:  10.0 \n",
      "\n",
      "The aim here seems to be to avoid ripe, opulent fruit in favor of an elegantly streamlined wine you might call Chablisian. The result is bone dry, high in aciditiy and lean, with mineral and citrus flavors. This is against the grain these days for fruity Chards.\n",
      "Predicted:  36.24586 Actual:  40.0 \n",
      "\n",
      "Baked plum, fragrant blue flower, sweet baking spice, eucalyptus and a balsamic note are just some of the aromas you'll find on this bold, delicious wine. The round, smooth palate delivers layers of ripe wild cherry, raspberry compote, mocha, vanilla, star anise and a hint of raisin alongside velvety, enveloping tannins that give it a silky texture. Despite the big structure, it has an almost weightless feel.\n",
      "Predicted:  60.133064 Actual:  60.0 \n",
      "\n",
      "A power-packed heavyweight from Sonoma, this delivers a piercing black-fruit aroma and flavor profile. Cassis and plum flavors are tight and tasty, and the long, juicy finish indicates that it could evolve nicely. Anyone planning on drinking it soon should expect a punch. Elegance is not its strong suit right now.\n",
      "Predicted:  38.79049 Actual:  70.0 \n",
      "\n",
      "Nice and dry, with pleasant flavors of cherries, raspberries, mocha and sandalwood. A good wine to drink now with pork, ham, or a mushroom-olive tapenade on bruschetta.\n",
      "Predicted:  42.318775 Actual:  50.0 \n",
      "\n",
      "Fruit from Seven Hills and Spofford Station provides the solid frame of black cherry, licorice, and tannin. This is a blocky wine, monolithic but full-bodied; best paired with hearty red meat dishes.\n",
      "Predicted:  28.495188 Actual:  29.0 \n",
      "\n",
      "Deep dark berry aromas come with notes of vanilla, gritty spice and tobacco. Hard tannins require cushion and this has just enough to handle things. Blackberry, cassis, barrel spice and molasses flavors finish with savory oak notes, chocolate and lingering blackberry fruit. Drink through 2030.\n",
      "Predicted:  49.080227 Actual:  64.0 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ripe but basic on the nose, this has dusty apple and sweet, minerally notes that are not sugary. It feels a little blowsy, but there's ample acidic cut to frame the dry, flavors of melon, green banana and apple. This has a simple finish. A blend of 80% Xarello and 20% Riesling.\n",
      "Predicted:  14.5296755 Actual:  15.0 \n",
      "\n",
      "In 5–10 years, this rating may look conservative, but right now, this wine's tannins are just too rustic and tough to be certain of its future evolution. It's a massive wine overall, with brambly, briary fruit, tinged with clove, cedar and chocolate, and those drying, astringent tannins on the finish.\n",
      "Predicted:  72.45181 Actual:  125.0 \n",
      "\n",
      "This is a plush, meaty wine with a dark, almost purplish hue and remarkable persistence and presence on the palate. Black cherry, ripe blueberries, vanilla, roasted nut and spice appear nicely on the nose without overwhelming the natural fruit. It has a chewy, juicy feel with silky tannins and good length on the finish.\n",
      "Predicted:  26.92233 Actual:  25.0 \n",
      "\n",
      "A bit muted on the nose, but this nicely balanced, mouthfilling wine ofers juicy apple and melon flavors that coat the mouth, showing a touch of honeyed sweetness on the finish. Imported by American Estates Wines, Inc.\n",
      "Predicted:  23.176004 Actual:  24.0 \n",
      "\n",
      "This low-oaked wine is somewhat sour with a Lemonheads sensibility, light bodied and defined by minerality. The long-lasting finish is reminiscent of lemongrass and ginger.\n",
      "Predicted:  20.608574 Actual:  24.0 \n",
      "\n",
      "Released almost a full year ago, this wine has had a chance to settle into a groove in the bottle. It is a medium plum color, lightly scented with herb, green and black tea, and Bing cherry. The flavors are astringent and compact, with a pretty burst of cherry in the core.\n",
      "Predicted:  29.40406 Actual:  32.0 \n",
      "\n",
      "Simple and direct in cherry, blackberry and sandalwood flavors, this Merlot is for everyday drinking at a fair price. It has a nice, silky texture.\n",
      "Predicted:  10.332482 Actual:  10.0 \n",
      "\n",
      "The color is a bit murky, but the wine offers sound, solid varietal aromas and plenty of sweet fruit. It's definitely front-loaded, with sweet cherry/berry and a nicely managed finish with a lick of chocolate. It shows the California influence of the winemaker, who is based in Santa Rosa.\n",
      "Predicted:  41.068443 Actual:  39.0 \n",
      "\n",
      "Made from 89% of the indigenous grape Karasakiz and 11% Merlot, this wine presents scents of strawberry and orange blossom. It comes on bright with flavors of cherry and clementine, but as smooth tannins coat the mouth, notes of anise, violet and smoke join the chorus. The finish is also bright, with lingering flavors of smoke and flowers.\n",
      "Predicted:  24.653269 Actual:  20.0 \n",
      "\n",
      "Give it air time and it'll give back floral raspberry and cherry aromas in front of a racy, forward-style palate that's got cherry and red plum flavors and integrated spice. Not overbearing; clean and dry on the finish. Atypical for a Carmenère-led prestige wine; it's more streamlined and red in character.\n",
      "Predicted:  22.29295 Actual:  24.0 \n",
      "\n",
      "Tropical fruit and citrus lead on this clean, refreshing Chardonnay from the folks at Rustenberg. Medium-bodied with balanced fruit and acidity, the wine offers an easygoing character that will pair well with spicy Chinese or Thai cuisine.\n",
      "Predicted:  10.959269 Actual:  11.0 \n",
      "\n",
      "This is a Chardonnay that showcases the best of what South Africa can offer: fresh fruit, elegant minerality, good value. The nose of citrus and flowers is both flirty and sophisticated, and the palate is friendly but complex, with mingling fruit and spice. Everything about the wine makes an impression  from start to finish.\n",
      "Predicted:  25.813036 Actual:  18.0 \n",
      "\n",
      "Pale and a bit rusty in color, this modest little wine offers nothing beyond faint pine and earth aromas and herbal, tomato-like flavors.\n",
      "Predicted:  15.57051 Actual:  15.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compare predictions with actual values for the first few items in our test dataset\n",
    "num_predictions = 40\n",
    "diff = 0\n",
    "\n",
    "for i in range(num_predictions):\n",
    "    val = predictions[i]\n",
    "    print(description_test.iloc[i])\n",
    "    print('Predicted: ', val[0], 'Actual: ', labels_test.iloc[i], '\\n')\n",
    "    diff += abs(val[0] - labels_test.iloc[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average prediction difference:  7.250338554382324\n"
     ]
    }
   ],
   "source": [
    "# Compare the average difference between actual price and the model's predicted price\n",
    "print('Average prediction difference: ', diff / num_predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting an average prediction difference of 7.25 is really good.  "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "wine prediction.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
